{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handwritten digit recognizer\n",
    "\n",
    "This notebook is an example of how we can implement deep learning models using Keras (wrapper for tensorflow).\n",
    "Here we use the famous MNIST data set. We will see how to implement: Complexified CNN: batch-norm + data augmentation + dropout. Further, we'll test transfer learning approach using vgg16 as a pretrained model.\n",
    "\n",
    " <b>Contents:</b>\n",
    "* A. Simple neuron (vanilla approach)\n",
    "* B. MLP\n",
    "* C. MLP with Dropout + BatchNorm\n",
    "* D. CNN with Dropout + BatchNorm + DataAugmentation\n",
    "\n",
    "### Importing utils and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from utils import *\n",
    "from __future__ import division, print_function\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download of Data and Viz\n",
    "### What does it look like ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIEAAAEVCAYAAAB3+fUzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4AVE7iXwAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110784470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(x_train,y_train),(x_test,y_test) = mnist.load_data()\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2,ncols=10,figsize=(20,5))\n",
    "ax = ax.ravel()\n",
    "\n",
    "for i in range(20):\n",
    "    ax[i].imshow(x_train[i],cmap = plt.get_cmap('gray'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x129c14e48>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMvxSUYZfKsrwS0X9HylnCMELbGlCAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x129a73ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[3,:,:], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. Simple Neuron\n",
    "Let's begin wih a simple neuron using a softmax activation function. Remember it's a vanilla approach ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of categories: 10\n"
     ]
    }
   ],
   "source": [
    "# download of data\n",
    "(x_train,y_train),(x_test,y_test) = mnist.load_data()\n",
    "\n",
    "# obtaining a vector of 784 for the 28x28 images\n",
    "num_pixels = x_train.shape[1] * x_train.shape[2]\n",
    "x_train = x_train.reshape(x_train.shape[0], num_pixels).astype('float32')\n",
    "x_test = x_test.reshape(x_test.shape[0], num_pixels).astype('float32')\n",
    "\n",
    "# normalizing between 0 and 1\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "print('Number of categories:',y_train.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 10)                7850      \n",
      "=================================================================\n",
      "Total params: 7,850.0\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def neuron_vanilla():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(10,activation='softmax',input_dim=num_pixels))\n",
    "    \n",
    "    model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = neuron_vanilla()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 1s - loss: 0.5433 - acc: 0.8622 - val_loss: 0.3319 - val_acc: 0.9102\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 1s - loss: 0.3237 - acc: 0.9112 - val_loss: 0.2921 - val_acc: 0.9194\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 1s - loss: 0.2957 - acc: 0.9180 - val_loss: 0.2796 - val_acc: 0.9232\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 1s - loss: 0.2825 - acc: 0.9214 - val_loss: 0.2735 - val_acc: 0.9238\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 1s - loss: 0.2739 - acc: 0.9241 - val_loss: 0.2698 - val_acc: 0.9247\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 1s - loss: 0.2679 - acc: 0.9251 - val_loss: 0.2662 - val_acc: 0.9258\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 1s - loss: 0.2638 - acc: 0.9268 - val_loss: 0.2645 - val_acc: 0.9275\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 1s - loss: 0.2599 - acc: 0.9283 - val_loss: 0.2663 - val_acc: 0.9267\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 1s - loss: 0.2571 - acc: 0.9290 - val_loss: 0.2643 - val_acc: 0.9273\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 1s - loss: 0.2547 - acc: 0.9298 - val_loss: 0.2619 - val_acc: 0.9271\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12b6fd160>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train, validation_data =(x_test,y_test),epochs=10,batch_size=64, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.261912576297 - accuracy:  0.9271\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x_test,y_test,verbose=0)\n",
    "print('loss: ', scores[0],'- accuracy: ', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. MLP - first approach \n",
    "Let's opt for a simple MLP, with 2 hidden layers and 256 hidden units per layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 269,322.0\n",
      "Trainable params: 269,322\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def MLP():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(256,activation='relu',input_dim=num_pixels))\n",
    "    model.add(Dense(256,activation='relu'))\n",
    "    \n",
    "    model.add(Dense(10,activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = MLP()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 5s - loss: 0.2220 - acc: 0.9342 - val_loss: 0.1055 - val_acc: 0.9675\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 5s - loss: 0.0861 - acc: 0.9724 - val_loss: 0.0863 - val_acc: 0.9748\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 4s - loss: 0.0565 - acc: 0.9823 - val_loss: 0.0744 - val_acc: 0.9768\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 4s - loss: 0.0414 - acc: 0.9869 - val_loss: 0.0870 - val_acc: 0.9731\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 5s - loss: 0.0329 - acc: 0.9895 - val_loss: 0.0710 - val_acc: 0.9795\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 4s - loss: 0.0257 - acc: 0.9912 - val_loss: 0.0867 - val_acc: 0.9747\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 4s - loss: 0.0208 - acc: 0.9930 - val_loss: 0.0756 - val_acc: 0.9799\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 5s - loss: 0.0212 - acc: 0.9929 - val_loss: 0.0773 - val_acc: 0.9811\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 5s - loss: 0.0164 - acc: 0.9946 - val_loss: 0.0862 - val_acc: 0.9803\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 5s - loss: 0.0138 - acc: 0.9955 - val_loss: 0.0890 - val_acc: 0.9801\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12f5060f0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train, validation_data =(x_test,y_test),epochs=10,batch_size=64, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.0889613848126 - accuracy:  0.9801\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x_test,y_test,verbose=0)\n",
    "print('loss: ', scores[0],'- accuracy: ', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C. MLP - Dropout and Batch-Norm\n",
    "Let's opt for a Dropout and BatchNormalization for reducing overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 271,370.0\n",
      "Trainable params: 270,346.0\n",
      "Non-trainable params: 1,024.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def MLP_b():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(256,activation='relu', input_dim=num_pixels))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "              \n",
    "    model.add(Dense(256,activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Dense(10,activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = MLP_b()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 10s - loss: 0.2697 - acc: 0.9178 - val_loss: 0.1093 - val_acc: 0.9656\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 9s - loss: 0.1386 - acc: 0.9567 - val_loss: 0.0959 - val_acc: 0.9695\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 9s - loss: 0.1115 - acc: 0.9646 - val_loss: 0.0791 - val_acc: 0.9751\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 9s - loss: 0.0957 - acc: 0.9698 - val_loss: 0.0684 - val_acc: 0.9779\n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 9s - loss: 0.0844 - acc: 0.9733 - val_loss: 0.0702 - val_acc: 0.9771\n",
      "Epoch 6/15\n",
      "60000/60000 [==============================] - 9s - loss: 0.0762 - acc: 0.9761 - val_loss: 0.0680 - val_acc: 0.9783\n",
      "Epoch 7/15\n",
      "60000/60000 [==============================] - 9s - loss: 0.0709 - acc: 0.9770 - val_loss: 0.0664 - val_acc: 0.9806\n",
      "Epoch 8/15\n",
      "60000/60000 [==============================] - 9s - loss: 0.0607 - acc: 0.9799 - val_loss: 0.0598 - val_acc: 0.9804\n",
      "Epoch 9/15\n",
      "60000/60000 [==============================] - 9s - loss: 0.0587 - acc: 0.9807 - val_loss: 0.0640 - val_acc: 0.9813\n",
      "Epoch 10/15\n",
      "60000/60000 [==============================] - 9s - loss: 0.0529 - acc: 0.9821 - val_loss: 0.0621 - val_acc: 0.9804\n",
      "Epoch 11/15\n",
      "60000/60000 [==============================] - 9s - loss: 0.0528 - acc: 0.9833 - val_loss: 0.0599 - val_acc: 0.9816\n",
      "Epoch 12/15\n",
      "60000/60000 [==============================] - 9s - loss: 0.0464 - acc: 0.9845 - val_loss: 0.0566 - val_acc: 0.9836\n",
      "Epoch 13/15\n",
      "60000/60000 [==============================] - 9s - loss: 0.0426 - acc: 0.9860 - val_loss: 0.0648 - val_acc: 0.9810\n",
      "Epoch 14/15\n",
      "60000/60000 [==============================] - 9s - loss: 0.0433 - acc: 0.9857 - val_loss: 0.0582 - val_acc: 0.9825\n",
      "Epoch 15/15\n",
      "60000/60000 [==============================] - 9s - loss: 0.0410 - acc: 0.9860 - val_loss: 0.0585 - val_acc: 0.9825\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x127aa8940>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train, validation_data =(x_test,y_test),epochs=15,batch_size=64, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.0584942561736 - accuracy:  0.9825\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x_test,y_test,verbose=0)\n",
    "print('loss: ', scores[0],'- accuracy: ', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D. Complexified CNN \n",
    "With Data-Augmentation - Batch-Normalization + Dropout + Conv2D + MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reshaping data\n",
    "Here we take the images as a matrix of shape (height, width, depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Downloading data\n",
    "(x_train,y_train),(x_test,y_test) = mnist.load_data()\n",
    "\n",
    "# reshaping the images for the conv2D (channels last)\n",
    "x_train = x_train.reshape(x_train.shape[0],28,28,1).astype('float32')\n",
    "x_test = x_test.reshape(x_test.shape[0],28,28,1).astype('float32')\n",
    "\n",
    "# one hot encode for the categories\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_samples = x_train.shape[0]\n",
    "validation_samples = x_test.shape[0]\n",
    "\n",
    "data_gen_train = ImageDataGenerator(rescale=1./255,\n",
    "                              rotation_range=8,\n",
    "                              width_shift_range=0.1,\n",
    "                              height_shift_range=0.1,\n",
    "                              shear_range=0.3,\n",
    "                              zoom_range=0.1,\n",
    "                              horizontal_flip=False)\n",
    "\n",
    "data_gen_test = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = data_gen_train.flow(x_train, y_train, batch_size = batch_size)\n",
    "validation_generator = data_gen_test.flow(x_test, y_test, batch_size = batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 32)        832       \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 24, 24, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 20, 20, 32)        25632     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 10, 10, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 64)          18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 6, 6, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 3, 3, 64)          256       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 175,338.0\n",
      "Trainable params: 174,442.0\n",
      "Non-trainable params: 896.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def complex_conv_model():\n",
    "    \n",
    "    # creating the convnet model\n",
    "    model = Sequential()\n",
    "    \n",
    "    # first convo block\n",
    "    model.add(Conv2D(32,(5,5), activation='relu', input_shape = (28,28,1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(32,(5,5), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # two convo block\n",
    "    model.add(Conv2D(64,(3,3),activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64,(3,3),activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(BatchNormalization())\n",
    " \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "        \n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "              \n",
    "    model.add(Dense(10,activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = complex_conv_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "937/937 [==============================] - 285s - loss: 0.5173 - acc: 0.8426 - val_loss: 0.0575 - val_acc: 0.9804\n",
      "Epoch 2/10\n",
      "937/937 [==============================] - 282s - loss: 0.1700 - acc: 0.9502 - val_loss: 0.0394 - val_acc: 0.9864\n",
      "Epoch 3/10\n",
      "297/937 [========>.....................] - ETA: 183s - loss: 0.1376 - acc: 0.9605"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-5eca98694f5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         validation_steps = validation_samples // batch_size)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/deepenv/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deepenv/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_q_size, workers, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1095\u001b[0m                                         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m                                         \u001b[0mpickle_safe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle_safe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1097\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deepenv/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deepenv/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_q_size, workers, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1874\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   1875\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1876\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1877\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1878\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deepenv/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1618\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deepenv/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2071\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2072\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2073\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2074\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2075\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deepenv/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deepenv/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deepenv/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m~/anaconda3/envs/deepenv/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deepenv/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit_generator(train_generator,\n",
    "        steps_per_epoch = train_samples // batch_size,\n",
    "        epochs=10,\n",
    "        validation_data = validation_generator,\n",
    "        validation_steps = validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visual check on small sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_generator(validation_generator,steps=validation_generator.n/batch_size) \n",
    "predictions = [np.argmax(i) for i in np.round(predictions)]\n",
    "y_tst = [np.argmax(i) for i in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted digitis</th>\n",
       "      <th>true digits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    predicted digitis  true digits\n",
       "0                   9            7\n",
       "1                   6            2\n",
       "2                   0            1\n",
       "3                   2            0\n",
       "4                   7            4\n",
       "5                   4            1\n",
       "6                   4            4\n",
       "7                   4            9\n",
       "8                   4            5\n",
       "9                   6            9\n",
       "10                  6            0\n",
       "11                  4            6\n",
       "12                  7            9\n",
       "13                  9            0\n",
       "14                  3            1\n",
       "15                  4            5\n",
       "16                  5            9\n",
       "17                  5            7\n",
       "18                  8            3\n",
       "19                  7            4\n",
       "20                  3            9\n",
       "21                  7            6\n",
       "22                  2            6\n",
       "23                  7            5\n",
       "24                  0            4\n",
       "25                  2            0\n",
       "26                  4            7\n",
       "27                  1            4\n",
       "28                  1            0\n",
       "29                  6            1\n",
       "30                  6            3\n",
       "31                  9            1\n",
       "32                  2            3\n",
       "33                  8            4\n",
       "34                  7            7\n",
       "35                  2            2\n",
       "36                  0            7\n",
       "37                  1            1\n",
       "38                  5            2\n",
       "39                  0            1\n",
       "40                  9            1\n",
       "41                  1            7\n",
       "42                  7            4\n",
       "43                  0            2\n",
       "44                  6            3\n",
       "45                  0            5\n",
       "46                  8            1\n",
       "47                  6            2\n",
       "48                  8            4\n",
       "49                  1            4"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'true digits':y_tst[:50],\n",
    "              'predicted digitis':predictions[:50]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python (deepenv)",
   "language": "python",
   "name": "deepenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
